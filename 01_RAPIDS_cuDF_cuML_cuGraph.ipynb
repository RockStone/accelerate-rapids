{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/adbreind/accelerate-rapids/blob/master/01_RAPIDS_cuDF_cuML_cuGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scfLT2i0MLyD"
   },
   "source": [
    "# Environment Sanity Check #\n",
    "\n",
    "Click the _Runtime_ dropdown at the top of the page, then _Change Runtime Type_ and confirm the instance type is _GPU_.\n",
    "\n",
    "Check the output of `!nvidia-smi` to make sure you've been allocated a Tesla T4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "B0C8IV5TQnjN",
    "outputId": "5d96e036-e3fa-4306-a554-65c6592d782d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 30 22:13:01 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   50C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "m0jdXBRiDSzj",
    "outputId": "06cba979-996e-4aa9-ac1a-ba1ff14422e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-09-30 22:13:02--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
      "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
      "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 58468498 (56M) [application/x-sh]\n",
      "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
      "\n",
      "Miniconda3-4.5.4-Li 100%[===================>]  55.76M  61.4MB/s    in 0.9s    \n",
      "\n",
      "2019-09-30 22:13:03 (61.4 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
      "\n",
      "PREFIX=/usr/local\n",
      "installing: python-3.6.5-hc3d631a_2 ...\n",
      "Python 3.6.5 :: Anaconda, Inc.\n",
      "installing: ca-certificates-2018.03.07-0 ...\n",
      "installing: conda-env-2.6.0-h36134e3_1 ...\n",
      "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
      "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
      "installing: libffi-3.2.1-hd88cf55_4 ...\n",
      "installing: ncurses-6.1-hf484d3e_0 ...\n",
      "installing: openssl-1.0.2o-h20670df_0 ...\n",
      "installing: tk-8.6.7-hc745277_3 ...\n",
      "installing: xz-5.2.4-h14c3975_4 ...\n",
      "installing: yaml-0.1.7-had09818_2 ...\n",
      "installing: zlib-1.2.11-ha838bed_2 ...\n",
      "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
      "installing: readline-7.0-ha6073c6_4 ...\n",
      "installing: sqlite-3.23.1-he433501_0 ...\n",
      "installing: asn1crypto-0.24.0-py36_0 ...\n",
      "installing: certifi-2018.4.16-py36_0 ...\n",
      "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
      "installing: idna-2.6-py36h82fb2a8_1 ...\n",
      "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
      "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
      "installing: pysocks-1.6.8-py36_0 ...\n",
      "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
      "installing: six-1.11.0-py36h372c433_1 ...\n",
      "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
      "installing: setuptools-39.2.0-py36_0 ...\n",
      "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
      "installing: wheel-0.31.1-py36_0 ...\n",
      "installing: pip-10.0.1-py36_0 ...\n",
      "installing: pyopenssl-18.0.0-py36_0 ...\n",
      "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
      "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
      "installing: conda-4.5.4-py36_0 ...\n",
      "installation finished.\n",
      "WARNING:\n",
      "    You currently have a PYTHONPATH environment variable set. This may cause\n",
      "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
      "    For best results, please verify that your PYTHONPATH only points to\n",
      "    directories of packages that are compatible with the Python interpreter\n",
      "    in Miniconda3: /usr/local\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local\n",
      "\n",
      "  added / updated specs: \n",
      "    - cudatoolkit=10.0\n",
      "    - cudf=0.9\n",
      "    - cugraph=0.9\n",
      "    - cuml=0.9\n",
      "    - python=3.6\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    re2-2019.09.01             |       he1b5a44_0         431 KB  conda-forge\n",
      "    cudatoolkit-10.0.130       |                0       380.0 MB  nvidia\n",
      "    brotli-1.0.7               |    he1b5a44_1000         1.0 MB  conda-forge\n",
      "    cugraph-0.9.0              |           py36_0         1.3 MB  rapidsai\n",
      "    readline-8.0               |       hf8c457e_0         441 KB  conda-forge\n",
      "    dlpack-0.2                 |       he1b5a44_1          13 KB  conda-forge\n",
      "    numba-0.45.1               |np116py36hf484d3e_0         3.2 MB  numba\n",
      "    nccl-2.4.6.1               |       cuda10.0_0        66.6 MB  nvidia\n",
      "    cffi-1.12.3                |   py36h8022711_0         218 KB  conda-forge\n",
      "    ncurses-6.1                |    hf484d3e_1002         1.3 MB  conda-forge\n",
      "    zlib-1.2.11                |    h516909a_1006         105 KB  conda-forge\n",
      "    double-conversion-3.1.5    |       he1b5a44_1          85 KB  conda-forge\n",
      "    uriparser-0.9.3            |       he1b5a44_1          49 KB  conda-forge\n",
      "    c-ares-1.15.0              |    h516909a_1001         100 KB  conda-forge\n",
      "    tk-8.6.9                   |    hed695b0_1003         3.2 MB  conda-forge\n",
      "    python-3.6.7               |    h357f687_1005        34.6 MB  conda-forge\n",
      "    cython-0.29.13             |   py36he1b5a44_0         2.2 MB  conda-forge\n",
      "    nvstrings-0.9.0            |           py36_0         124 KB  rapidsai\n",
      "    pytz-2019.2                |             py_0         228 KB  conda-forge\n",
      "    parquet-cpp-1.5.1          |                2           3 KB  conda-forge\n",
      "    librmm-0.9.0               |       cuda10.0_0          44 KB  rapidsai\n",
      "    bzip2-1.0.8                |       h516909a_1         397 KB  conda-forge\n",
      "    liblapack-3.8.0            |      12_openblas          10 KB  conda-forge\n",
      "    _libgcc_mutex-0.1          |             main           3 KB\n",
      "    glog-0.4.0                 |       he1b5a44_1         104 KB  conda-forge\n",
      "    icu-64.2                   |       he1b5a44_1        12.6 MB  conda-forge\n",
      "    arrow-cpp-0.14.1           |   py36h5ac5442_4        17.3 MB  conda-forge\n",
      "    libprotobuf-3.8.0          |       h8b12597_0         4.7 MB  conda-forge\n",
      "    libopenblas-0.3.7          |       h6e990d7_1         7.6 MB  conda-forge\n",
      "    ca-certificates-2019.9.11  |       hecc5488_0         144 KB  conda-forge\n",
      "    snappy-1.1.7               |    he1b5a44_1002          39 KB  conda-forge\n",
      "    libstdcxx-ng-9.1.0         |       hdf63c60_0         4.0 MB\n",
      "    numpy-1.16.4               |   py36h95a1406_0         4.3 MB  conda-forge\n",
      "    rmm-0.9.0                  |           py36_0          14 KB  rapidsai\n",
      "    setuptools-41.2.0          |           py36_0         634 KB  conda-forge\n",
      "    libcumlprims-0.9.0         |       cuda10.0_0         3.9 MB  nvidia\n",
      "    fastavro-0.22.5            |   py36h516909a_0         405 KB  conda-forge\n",
      "    pip-19.2.3                 |           py36_0         1.9 MB  conda-forge\n",
      "    cuml-0.9.1                 |  cuda10.0_py36_0         5.9 MB  rapidsai\n",
      "    libgcc-ng-9.1.0            |       hdf63c60_0         8.1 MB\n",
      "    openssl-1.1.1c             |       h516909a_0         2.1 MB  conda-forge\n",
      "    grpc-cpp-1.23.0            |       h18db393_0         4.5 MB  conda-forge\n",
      "    libcudf-0.9.0              |       cuda10.0_0        29.1 MB  rapidsai\n",
      "    gflags-2.2.2               |    he1b5a44_1001         177 KB  conda-forge\n",
      "    libevent-2.1.10            |       h72c5cf5_0         1.3 MB  conda-forge\n",
      "    thrift-cpp-0.12.0          |    hf3afdfd_1004         2.4 MB  conda-forge\n",
      "    pycparser-2.19             |           py36_1         173 KB  conda-forge\n",
      "    llvmlite-0.29.0            |   py36hf484d3e_0        17.7 MB  numba\n",
      "    lz4-c-1.8.3                |    he1b5a44_1001         187 KB  conda-forge\n",
      "    certifi-2019.9.11          |           py36_0         147 KB  conda-forge\n",
      "    pandas-0.24.2              |   py36hb3f55d8_0        11.1 MB  conda-forge\n",
      "    pyarrow-0.14.1             |   py36h8b68381_2         2.8 MB  conda-forge\n",
      "    python-dateutil-2.8.0      |             py_0         219 KB  conda-forge\n",
      "    zstd-1.4.0                 |       h3b9ef0a_0         928 KB  conda-forge\n",
      "    six-1.12.0                 |        py36_1000          22 KB  conda-forge\n",
      "    boost-cpp-1.70.0           |       h8e57a91_2        21.1 MB  conda-forge\n",
      "    libnvstrings-0.9.0         |       cuda10.0_0        16.8 MB  rapidsai\n",
      "    cudf-0.9.0                 |           py36_0         4.8 MB  rapidsai\n",
      "    libcugraph-0.9.0           |       cuda10.0_0        11.3 MB  rapidsai\n",
      "    xz-5.2.4                   |    h14c3975_1001         366 KB  conda-forge\n",
      "    wheel-0.33.6               |           py36_0          35 KB  conda-forge\n",
      "    libblas-3.8.0              |      12_openblas          10 KB  conda-forge\n",
      "    libcblas-3.8.0             |      12_openblas          10 KB  conda-forge\n",
      "    sqlite-3.29.0              |       hcee41ef_1         1.9 MB  conda-forge\n",
      "    libcuml-0.9.1              |       cuda10.0_0        29.7 MB  rapidsai\n",
      "    libgfortran-ng-7.3.0       |       hdf63c60_0         1.3 MB\n",
      "    libffi-3.2.1               |    he1b5a44_1006          46 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       727.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    _libgcc_mutex:     0.1-main                              \n",
      "    arrow-cpp:         0.14.1-py36h5ac5442_4      conda-forge\n",
      "    boost-cpp:         1.70.0-h8e57a91_2          conda-forge\n",
      "    brotli:            1.0.7-he1b5a44_1000        conda-forge\n",
      "    bzip2:             1.0.8-h516909a_1           conda-forge\n",
      "    c-ares:            1.15.0-h516909a_1001       conda-forge\n",
      "    cudatoolkit:       10.0.130-0                 nvidia     \n",
      "    cudf:              0.9.0-py36_0               rapidsai   \n",
      "    cugraph:           0.9.0-py36_0               rapidsai   \n",
      "    cuml:              0.9.1-cuda10.0_py36_0      rapidsai   \n",
      "    cython:            0.29.13-py36he1b5a44_0     conda-forge\n",
      "    dlpack:            0.2-he1b5a44_1             conda-forge\n",
      "    double-conversion: 3.1.5-he1b5a44_1           conda-forge\n",
      "    fastavro:          0.22.5-py36h516909a_0      conda-forge\n",
      "    gflags:            2.2.2-he1b5a44_1001        conda-forge\n",
      "    glog:              0.4.0-he1b5a44_1           conda-forge\n",
      "    grpc-cpp:          1.23.0-h18db393_0          conda-forge\n",
      "    icu:               64.2-he1b5a44_1            conda-forge\n",
      "    libblas:           3.8.0-12_openblas          conda-forge\n",
      "    libcblas:          3.8.0-12_openblas          conda-forge\n",
      "    libcudf:           0.9.0-cuda10.0_0           rapidsai   \n",
      "    libcugraph:        0.9.0-cuda10.0_0           rapidsai   \n",
      "    libcuml:           0.9.1-cuda10.0_0           rapidsai   \n",
      "    libcumlprims:      0.9.0-cuda10.0_0           nvidia     \n",
      "    libevent:          2.1.10-h72c5cf5_0          conda-forge\n",
      "    libgfortran-ng:    7.3.0-hdf63c60_0                      \n",
      "    liblapack:         3.8.0-12_openblas          conda-forge\n",
      "    libnvstrings:      0.9.0-cuda10.0_0           rapidsai   \n",
      "    libopenblas:       0.3.7-h6e990d7_1           conda-forge\n",
      "    libprotobuf:       3.8.0-h8b12597_0           conda-forge\n",
      "    librmm:            0.9.0-cuda10.0_0           rapidsai   \n",
      "    llvmlite:          0.29.0-py36hf484d3e_0      numba      \n",
      "    lz4-c:             1.8.3-he1b5a44_1001        conda-forge\n",
      "    nccl:              2.4.6.1-cuda10.0_0         nvidia     \n",
      "    numba:             0.45.1-np116py36hf484d3e_0 numba      \n",
      "    numpy:             1.16.4-py36h95a1406_0      conda-forge\n",
      "    nvstrings:         0.9.0-py36_0               rapidsai   \n",
      "    pandas:            0.24.2-py36hb3f55d8_0      conda-forge\n",
      "    parquet-cpp:       1.5.1-2                    conda-forge\n",
      "    pyarrow:           0.14.1-py36h8b68381_2      conda-forge\n",
      "    python-dateutil:   2.8.0-py_0                 conda-forge\n",
      "    pytz:              2019.2-py_0                conda-forge\n",
      "    re2:               2019.09.01-he1b5a44_0      conda-forge\n",
      "    rmm:               0.9.0-py36_0               rapidsai   \n",
      "    snappy:            1.1.7-he1b5a44_1002        conda-forge\n",
      "    thrift-cpp:        0.12.0-hf3afdfd_1004       conda-forge\n",
      "    uriparser:         0.9.3-he1b5a44_1           conda-forge\n",
      "    zstd:              1.4.0-h3b9ef0a_0           conda-forge\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    ca-certificates:   2018.03.07-0                           --> 2019.9.11-hecc5488_0  conda-forge\n",
      "    certifi:           2018.4.16-py36_0                       --> 2019.9.11-py36_0      conda-forge\n",
      "    cffi:              1.11.5-py36h9745a5d_0                  --> 1.12.3-py36h8022711_0 conda-forge\n",
      "    libffi:            3.2.1-hd88cf55_4                       --> 3.2.1-he1b5a44_1006   conda-forge\n",
      "    libgcc-ng:         7.2.0-hdf63c60_3                       --> 9.1.0-hdf63c60_0                 \n",
      "    libstdcxx-ng:      7.2.0-hdf63c60_3                       --> 9.1.0-hdf63c60_0                 \n",
      "    ncurses:           6.1-hf484d3e_0                         --> 6.1-hf484d3e_1002     conda-forge\n",
      "    openssl:           1.0.2o-h20670df_0                      --> 1.1.1c-h516909a_0     conda-forge\n",
      "    pip:               10.0.1-py36_0                          --> 19.2.3-py36_0         conda-forge\n",
      "    pycparser:         2.18-py36hf9f622e_1                    --> 2.19-py36_1           conda-forge\n",
      "    python:            3.6.5-hc3d631a_2                       --> 3.6.7-h357f687_1005   conda-forge\n",
      "    readline:          7.0-ha6073c6_4                         --> 8.0-hf8c457e_0        conda-forge\n",
      "    setuptools:        39.2.0-py36_0                          --> 41.2.0-py36_0         conda-forge\n",
      "    six:               1.11.0-py36h372c433_1                  --> 1.12.0-py36_1000      conda-forge\n",
      "    sqlite:            3.23.1-he433501_0                      --> 3.29.0-hcee41ef_1     conda-forge\n",
      "    tk:                8.6.7-hc745277_3                       --> 8.6.9-hed695b0_1003   conda-forge\n",
      "    wheel:             0.31.1-py36_0                          --> 0.33.6-py36_0         conda-forge\n",
      "    xz:                5.2.4-h14c3975_4                       --> 5.2.4-h14c3975_1001   conda-forge\n",
      "    zlib:              1.2.11-ha838bed_2                      --> 1.2.11-h516909a_1006  conda-forge\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "# intall miniconda\n",
    "!wget -c https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
    "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
    "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
    "\n",
    "# install RAPIDS packages\n",
    "!conda install -q -y --prefix /usr/local -c nvidia -c rapidsai \\\n",
    "  -c numba -c conda-forge -c pytorch -c defaults \\\n",
    "  cudf=0.9 cuml=0.9 cugraph=0.9 python=3.6 cudatoolkit=10.0\n",
    "\n",
    "# set environment vars\n",
    "import sys, os, shutil\n",
    "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
    "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
    "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
    "\n",
    "# copy .so files to current working dir\n",
    "for fn in ['libcudf.so', 'librmm.so']:\n",
    "  shutil.copy('/usr/local/lib/'+fn, os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9oOCJ4NYMjY7"
   },
   "source": [
    "# cuDF and cuML Smoke Test \n",
    "\n",
    "_Note_: You must import nvstrings and nvcategory before cudf, else you'll get errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "EwaJSKuswsNi",
    "outputId": "2c5534d2-e517-4674-852b-124f37c8a4e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test\n",
      "0     1\n",
      "1     2\n",
      "2     3\n",
      "       test\n",
      "count   3.0\n",
      "mean    2.0\n",
      "std     1.0\n",
      "min     1.0\n",
      "25%     1.5\n",
      "50%     2.0\n",
      "75%     2.5\n",
      "max     3.0\n"
     ]
    }
   ],
   "source": [
    "import nvstrings, nvcategory, cudf\n",
    "\n",
    "gdf = cudf.DataFrame({'test':[1,2,3]})\n",
    "print(gdf)\n",
    "print(gdf.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "dCE8WhO3HpL_",
    "outputId": "505aec19-8acd-4cbe-9b0e-a38bda9fb68c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import cuml\n",
    "\n",
    "df_float = cudf.DataFrame()\n",
    "df_float['0'] = [1.0, 2.0, 5.0]\n",
    "df_float['1'] = [4.0, 2.0, 1.0]\n",
    "\n",
    "dbscan_float = cuml.DBSCAN(eps=1.0, min_samples=1)\n",
    "dbscan_float.fit(df_float)\n",
    "\n",
    "print(dbscan_float.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "nS7T-indP19Y",
    "outputId": "978cc86a-5e99-4912-d3bd-a2e63bbf6c64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>vertices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels  vertices\n",
       "0       0         0\n",
       "1       0         1\n",
       "2       0         2\n",
       "3       3         3"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cugraph\n",
    "\n",
    "G = cugraph.Graph()\n",
    "G.add_edge_list(cudf.Series([0, 1, 2, 2], dtype='int32'),\n",
    "                cudf.Series([1, 2, 0, 3], dtype='int32'))\n",
    "cugraph.strongly_connected_components(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mWUXnTj7_K-v",
    "outputId": "ea803c8b-6b1e-46d7-9fd2-52ee156d08f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTALL SUCCESS\n"
     ]
    }
   ],
   "source": [
    "print(\"INSTALL SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3KBRCWOYbME"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('stopping here on purpose' # post-install)? (<ipython-input-2-f82bf4183d56>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-f82bf4183d56>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print 'stopping here on purpose' # post-install\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('stopping here on purpose' # post-install)?\n"
     ]
    }
   ],
   "source": [
    "print 'stopping here on purpose' # post-install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cABlcPbEl2dj"
   },
   "source": [
    "# Add GPU to Pandas-Style Analytics with cuDF\n",
    "\n",
    "## Beer Review Data Analysis\n",
    "\n",
    "In this lab, we'll practice using Pandas by exploring a dataset of beer reviews. \n",
    "\n",
    "First we'll retrieve a small slice of the data. The full beer review dataset is surprisingly large ... or maybe not that surprising, since it seems like the kind of job that would be hard to give up so long as one more beer was out there :)\n",
    "\n",
    "First we'll import Pandas and retrieve the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YczFxJov_vks"
   },
   "outputs": [],
   "source": [
    "df = cudf.read_csv('beer_small.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szIhoOFdmkhJ"
   },
   "source": [
    "How many reviews are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PSgtgvWr_wDq"
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hEVuHpglmpua"
   },
   "source": [
    "How can we tell if there are missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBuxeL_8_1EL"
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XFeUtBwhmzAk"
   },
   "source": [
    "Since most reviews have data for most fields, let's drop the records with incomplete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDvu2JFS_2e0"
   },
   "outputs": [],
   "source": [
    "df2 = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CtQ0MDDm6Z1"
   },
   "outputs": [],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpDFaemYm_uL"
   },
   "source": [
    "Let's get summary statistics for the numeric columns ... things like review score and ABV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGrg_2hnm7bs"
   },
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nC8dBxtnJy2"
   },
   "source": [
    "There are some really low-alcohol beers in there ... maybe even bogus data.\n",
    "\n",
    "Find all entries with ABV less than 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1CcqFn8nF-i"
   },
   "outputs": [],
   "source": [
    "low_abv = df2[df2.beer_abv < 1]\n",
    "\n",
    "low_abv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9V3yyGMtniaG"
   },
   "source": [
    "How many of these reviews are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgD-x03CnTY8"
   },
   "outputs": [],
   "source": [
    "len(low_abv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUMswWNQnnWt"
   },
   "source": [
    "Some of these are multiple reviews for the same beer, which is allowed (and even encouraged). Let's group by beer and count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lE07kGWRnlgD"
   },
   "outputs": [],
   "source": [
    "grouping = low_abv.groupby('beer_name')\n",
    "grouping.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_GJw0y9ko2vb"
   },
   "source": [
    "How consistent are the O'Douls overall scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6IYu8cimnysJ"
   },
   "outputs": [],
   "source": [
    "scores = low_abv[low_abv.beer_name==\"O'Doul's\"]['review_overall']\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eav0-yydpN3p"
   },
   "source": [
    "Let's plot a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvPHQoVno_Mv"
   },
   "outputs": [],
   "source": [
    "scores.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9MfIBLAbpYSp"
   },
   "source": [
    "What are the mean and sd for the O'Doul's overall scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Os6dqMgNpNAV"
   },
   "outputs": [],
   "source": [
    "scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-_P9KB1ypl1y"
   },
   "source": [
    "In the full dataset, can we count beers by brewery, and then by style within that brewery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0gVxucCpRxV"
   },
   "outputs": [],
   "source": [
    "df2.groupby(['brewery_name', 'beer_style']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "evW99OPdeGTi"
   },
   "source": [
    "### Now we'll try and build up a slightly more complex report\n",
    "\n",
    "Step 1: Find all rows corresponsing to reviews where the beer style starts with \"American\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQ0I54mweRh_"
   },
   "outputs": [],
   "source": [
    "all_american = df2[df2.beer_style.str.startswith('American')]\n",
    "all_american"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTSS1H1AecYd"
   },
   "source": [
    "Next, make a dataframe with just the `beer_style` and `review_overall` fields for those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6HDs5WJejtj"
   },
   "outputs": [],
   "source": [
    "narrowed = all_american[['beer_style', 'review_overall']]\n",
    "narrowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nE0CsERyeovC"
   },
   "source": [
    "Now we'll make a boxplot to capture the range and variance of the ratings. Pandas will do all the work is we call the built-in API. Look for it here: https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdYvJnNv59F-"
   },
   "outputs": [],
   "source": [
    "narrowed.boxplot(by='beer_style', vert=False, figsize=(12,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GPU to Scikit-Learn-Style Modeling with cuML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Diamonds\n",
    "\n",
    "This dataset of diamond sales (http://ggplot2.tidyverse.org/reference/diamonds.html) is of moderate size (~55,000 records) and resembles data records that occur in many business scenarios.\n",
    "\n",
    "For each of the diamond sales records, we have the following properties:\n",
    "* price: price in US dollars ($326-$18,823)\n",
    "* carat: weight of the diamond (0.2-5.01)\n",
    "* cut: quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "* color: diamond colour, from J (worst) to D (best)\n",
    "* clarity: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "* x: length in mm (0-10.74)\n",
    "* y: width in mm (0-58.9)\n",
    "* z: depth in mm (0-31.8)\n",
    "* depth: total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43-79)\n",
    "* table: width of top of diamond relative to widest point (43-95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.read_csv('data/diamonds.csv')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"unnamed\" column is a row number in the dataset. It turns out that this row number -- which sounds like it should be meaningless -- actually leaks key data about the diamonds. \n",
    "\n",
    "Can you think of why this might be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(df.iloc[:,0], df['price'], ',') # , means just a pixel marker\n",
    "ax.set(xlabel='record #', ylabel='$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get rid of the row number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "df2[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Feautres\n",
    "\n",
    "Now ... computers are good with numbers, but what about those words? (\"Premium\", \"Ideal\", etc.)\n",
    "\n",
    "It turns out that not only do we need to convert them to numbers, but we often want to do that in a way that treats them as totally separate properties.\n",
    "\n",
    "That is, we consider the \"Ideal\"-ness of a diamond totally separately from the \"Premium\"-ness of that diamond, etc., and of course each diamond only has one of those properties. This is called \"one-hot encoding\" (or sometimes \"dummy variable encoding\" or \"one of k encoding\").\n",
    "\n",
    "Why do we do this? Wouldn't it make more sense to measure the goodness-of-cut along a numeric scale, almost like the carat weight?\n",
    "\n",
    "In theory, yes -- and in some case your team may want to do that. But without putting in a lot of work (or having the business domain knowledge) to get that right, we can approximate with this encoding that is, in essence, just a math trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df2.cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(df2.cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In many cases, Pandas can do these steps for us (although the Categorical type is useful to know about & use)\n",
    "df3 = pd.get_dummies(df2)\n",
    "\n",
    "df3.iloc[:3, 7:18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll split out a \"test set\" -- remember we want to be able to evaluate the model on records that it hasn't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df3.price\n",
    "\n",
    "X = df3.drop(columns='price')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baselines\n",
    "\n",
    "In this case we'll use the mean price of the diamonds as a (constant) baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our first \"baseline\" model just says for any diamond we might look at, its price is about $3900. Obviously this is usually going to be wrong, and often by a lot. But it's better than nother. Later we'll see how to compare a \"real\" model against this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll set up the model. As we said above, kNN is very simple ... but even complex models are easy to set up with this code library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "model = neigh.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, how did we do?\n",
    "\n",
    "For regression problems like this, we'll measure the accuracy of our predictions using RMSE (root mean squared error). This is a measure of \"how wrong\" we typically are in our predictions, measured in the units we are predicting (i.e., in this case, dollars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE %f\" % np.sqrt(mean_squared_error(y_test, y_pred)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So is that actually any good?\n",
    "\n",
    "One way to get an idea is to compare it to the mean and standard deviation of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.mean(), y_test.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Parametric Model: Linear Regression\n",
    "\n",
    "The canonical example of a parametric model is a linear regression model. Linear regression -- which you might have done by hand on a small amount of data in high school or a college stats class -- is simple, fast, robust, and performs reasonably well for many kinds of real-world data.\n",
    "\n",
    "In fact, linear regression is one of the two or three most widely used algorithms in the world for data modeling.\n",
    "\n",
    "Here's a simple version with one predictor and one response plotted against each other, along with a regression line:\n",
    "\n",
    "<img src=\"https://materials.s3.amazonaws.com/i/gyP3KGA.png\">\n",
    "\n",
    "How does the computer (or the student) figure out where to draw that regression line? The goal is to minimize the __error__.\n",
    "\n",
    "What is the error? The difference (or distance) between the true value and the value predicted by the regression line:\n",
    "\n",
    "<img src=\"https://materials.s3.amazonaws.com/i/cgvGCMg.jpg\" width=600>\n",
    "\n",
    "That might be getting into too much detail for this class, so let's just say we want to calculate the mathematically best-fit line.\n",
    "\n",
    "You can also notice that if the data itself does not embody a linear relationship, this approach may not work very well. Surprisingly, a lot of phenomena do have a large enough linear component that this algorithm often works. One thing that will help it fit complex data -- like your business records or our diamond sales -- is using more dimensions. That is, unlike the pictures here which just have one predictor (to make the pictures simple), we can use the same approach to calculate a response as a linear function of many dimensions. \n",
    "\n",
    "Let's fit a linear regression model to our diamonds dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "linear = lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linear.predict(X_test)\n",
    "print(\"RMSE %f\" % np.sqrt(mean_squared_error(y_test, y_pred)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model didn't fit quite as well as the kNN model (the RMSE here is larger, indicating our predictions are off by a few hundred more dollars). However, this model is very compact, since it is completely defined by about 27 parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients: %s\" % linear.coef_)\n",
    "\n",
    "print(\"Intercept: %s\" % linear.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And making a prediction requires just multiplying and then adding 26 pairs of numbers, so it is lightning fast, even on the tiniest embedded IoT device. Alternatively, if we want to make billions of predictions, we could do that in a second with higher-end server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab: Powerplant Output \n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant\n",
    "\n",
    "About the business problem: peaker plant operation\n",
    "\n",
    "What is in this dataset? Just under 10,000 observations of:\n",
    "\n",
    "* Temperature (AT) in the range 1.81°C and 37.11°C\n",
    "* Ambient Pressure (AP) in the range 992.89-1033.30 millibar,\n",
    "* Relative Humidity (RH) in the range 25.56% to 100.16%\n",
    "* Exhaust Vacuum (V) in the range 25.36-81.56 cm Hg\n",
    "* Net hourly electrical energy output (PE) 420.26-495.76 MW\n",
    "\n",
    "What is the goal? To model output (PE) based other measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/powerplant.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, think about your intuition, experience, or \"domain knowledge\" that might apply -- even if you don't know about power generation, you may have some ideas about atmospheric pressure and temperature, and how they might affect a combustion-based power output.\n",
    "\n",
    "Test those ideas by building some plots. With just 4 predictors, you can make plots with all of them. Notice anything interesting?\n",
    "\n",
    "Try to build a linear regression model for power output. (Hint: you can cut/paste a lot of the code we've already used in this notebook!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "01-RAPIDS-cuDF-cuML-cuGraph.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
