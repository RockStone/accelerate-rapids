{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://materials.s3.amazonaws.com/i/RAPIDS-logo-white.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYiqRSBOdaHG"
   },
   "source": [
    "# Why Are We Interested in RAPIDS? (and GPU, CUDA, Numba...)\n",
    "\n",
    "### Let's start by taking a really straightforward look at GPU benefit without RAPIDS\n",
    "\n",
    "Here are 1 million numbers and their square roots in (regular) Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnmmTYn_men9"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "numbers = list(range(1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHXLMQsKg3ki"
   },
   "outputs": [],
   "source": [
    "%%timeit \n",
    "\n",
    "s = [math.sqrt(x) for x in numbers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Im0OGhiRd40F"
   },
   "source": [
    "Using NumPy (https://numpy.org/) we can both vectorize our operation and leverage a native (C) implementation from Python.\n",
    "\n",
    "Don't know about NumPy? It's a core part of the SciPy stack, and provides an implementation of tensors (multi-dimensional array) and tensor math, where the underlying storage is native (not Python objects) and operations are implemented in native extenstion ... so it's Python-friendly, but much faster.\n",
    "\n",
    "The most common Python data science tools -- things like Pandas and Scikit-Learn -- are built on top of NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XfYFls87mYJ2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_numbers = np.array(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frDit5S2hGCO"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "np_s = np.sqrt(np_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLAhODzzeBko"
   },
   "source": [
    "That's pretty nice. Of course, maybe we just started out with Python as an easy target.\n",
    "\n",
    "Let's look at jitted compiled code with Numba.\n",
    "\n",
    "(Don't know about Numba? You're going to love it: a great JIT add-on that can target CPU as well as multiple flavors of GPU ... learn more at https://numba.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BfCEacOuFdnj"
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit\n",
    "def root(n):\n",
    "  return np.sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q2Q8kza1Fn7b"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "numba_s = root(np_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6qWPy5ReSuu"
   },
   "source": [
    "Not bad. But we're here for GPUs ... will the GPU help much?\n",
    "\n",
    "A few libraries make it easy to do matrix operations like this on GPU ... two of the most popular/famous are PyTorch and CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "\n",
    "gpu_numbers = cupy.array(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJj9HJdEhymu"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "gpu_squares = cupy.sqrt(gpu_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AxTfJClieiCk"
   },
   "source": [
    "Now things are getting interesting...\n",
    "\n",
    "*PyTorch, CuPy, and Numba can help us move tensor math and some Python functions to GPU ... but what about high-level data-science tooling like Pandas, Scikit-Learn, NetworkX ... and how about SQL?*\n",
    "\n",
    "That's what RAPIDS was created. Officially announced in October 2018, RAPIDS is now over one year old.\n",
    "\n",
    "Happy Birthday!\n",
    "\n",
    "<img src='https://materials.s3.amazonaws.com/i/rapidscake.jpeg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TuO03lL-fEnA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "01-Intro",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
