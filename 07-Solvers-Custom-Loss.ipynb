{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXnXTrORzdnk"
   },
   "source": [
    "# GPU Gradient Descent Solving\n",
    "\n",
    "Many traditional machine learning algorithms can be implemented on GPU.\n",
    "\n",
    "There may be more direct ways to use the GPU (e.g., RAPIDS) or faster solvers (e.g., L-BFGS, OWL-QN) for traditional problems.\n",
    "\n",
    "But in some cases, the deep learning toolkits can simplify challenging aspects -- e.g., via embeddings\n",
    "* https://abhadury.com/articles/2020-03/embeddings-for-recommender-systems\n",
    "* https://tech.instacart.com/deep-learning-with-emojis-not-math-660ba1ad6cdc\n",
    "\n",
    "And in other cases, we may want to use a custom loss to construct a model that maximizes a business objective, rather than just the likelihood of the model params.\n",
    "\n",
    "We'll take a look at a linear regression for the diamonds dataset using PyTorch where we want to\n",
    "* minimize RMSE\n",
    "* __but also__ minimize the number of undervalued diamonds\n",
    "\n",
    "This is an simple example of a common business scenario. \n",
    "\n",
    "Start with data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rbO5In_eyNRM"
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "input_file = \"data/diamonds.csv\"\n",
    "\n",
    "df = cudf.read_csv(input_file, header = 0)\n",
    "df2 = df.drop(df.columns[0], axis=1)\n",
    "df3 = cudf.get_dummies(df2, columns=['cut', 'color', 'clarity'])\n",
    "y = df3['price'].astype('double')\n",
    "X = df3.drop('price')\n",
    "\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "QffYtrWQxco9"
   },
   "outputs": [],
   "source": [
    "import cuml\n",
    "\n",
    "X_train, X_test, y_train, y_test = cuml.preprocessing.model_selection.train_test_split(X, y, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "xSDO8u0cMK0t"
   },
   "source": [
    "Now we'll start with a regular linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16R26WJ8MK0v"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_train_pyt, y_train_pyt, X_test_pyt, y_test_pyt = \\\n",
    "  torch.cuda.DoubleTensor(X_train.as_gpu_matrix()), \\\n",
    "  torch.cuda.DoubleTensor(y_train.to_gpu_array()),  \\\n",
    "  torch.cuda.DoubleTensor(X_test.as_gpu_matrix()),  \\\n",
    "  torch.cuda.DoubleTensor(y_test.to_gpu_array())\n",
    "\n",
    "train_ds = TensorDataset(X_train_pyt, y_train_pyt[:, None])\n",
    "\n",
    "print(len(train_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38OEw7cEDnNO"
   },
   "source": [
    "__Notice: We were able to pass our data from RAPIDS to PyTorch without copying, via support for__ `__cuda_array_interface__`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tfXZG0aTDQGV"
   },
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlyxHtIuMK0y"
   },
   "outputs": [],
   "source": [
    "batch_size, D_in, D_out = 200, 26, 1\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(D_in, D_out).double()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "SsbHf7GOMK01"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "history = []\n",
    "for epoch in range(250):\n",
    "    batch_losses = []\n",
    "    for i in range((len(train_ds) - 1) // batch_size + 1):\n",
    "        xb, yb = train_ds[i * batch_size: i * batch_size + batch_size]\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        batch_losses.append(loss.item()) # note the .item()\n",
    "    epoch_loss = np.sqrt(pd.Series(batch_losses).mean()) #not 100% accurate due to batch size diff, we'll fix that later\n",
    "    history.append(epoch_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Training RMSE for epoch {} = {}\".format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMEj-HQlMK04"
   },
   "source": [
    "Let's check our test set performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QSsDJw_UMK05"
   },
   "outputs": [],
   "source": [
    "# make predictions on test set:\n",
    "y_pred_pyt = model(X_test_pyt) #we're leaving out some \"best practices\" for simplicity\n",
    "print(y_pred_pyt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Zchyp5BFjkO"
   },
   "outputs": [],
   "source": [
    "print(y_test_pyt.shape)\n",
    "print(y_test_pyt.unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqneU9MGF_rR"
   },
   "outputs": [],
   "source": [
    "rmse1 = loss_fn(y_pred_pyt, y_test_pyt.unsqueeze(1)).sqrt()\n",
    "print(f\"Calulating Final Test RMSE: {rmse1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "337Phz_VMK0_"
   },
   "source": [
    "How does this compare to the std dev of the response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnpAIE0NMK1A"
   },
   "outputs": [],
   "source": [
    "y_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, how many of those predictions were below the true price? (Recall, in our business scenario we want to minimize this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred_pyt < y_test_pyt.unsqueeze(1)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Rkd1ymR-W75"
   },
   "source": [
    "## Ok, No Surprises - Now Let's Try Something A Bit More Interesting\n",
    "\n",
    "By customizing our loss function, we can optimize for *business loss* as opposed to the pure MSE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuALfNP7MK1P"
   },
   "outputs": [],
   "source": [
    "batch_size, D_in, D_out = 200, 26, 1\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(D_in, D_out).double()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll define our custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(pred, label):\n",
    "    sq = (label-pred)**2\n",
    "    mask = (pred < label)\n",
    "    sq[mask] = sq[mask]**(1.2)\n",
    "    return sq.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the larger losses, we need to slow our learning rate, and run more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-ffGutgMK1U"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "history = []\n",
    "for epoch in range(1500):\n",
    "    batch_losses = []\n",
    "    for i in range((len(train_ds) - 1) // batch_size + 1):\n",
    "        xb, yb = train_ds[i * batch_size: i * batch_size + batch_size]      \n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        batch_losses.append(loss.item()) # note the .item()\n",
    "    epoch_loss = np.sqrt(pd.Series(batch_losses).mean()) #not 100% accurate due to batch size diff, we'll fix that later\n",
    "    history.append(epoch_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Training sqrt-loss for epoch {} = {}\".format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have this dual-objective loss...\n",
    "\n",
    "Part 1: What is the RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pyt = model(X_test_pyt)\n",
    "rmse2 = torch.nn.MSELoss()(y_pred_pyt, y_test_pyt.unsqueeze(1)).sqrt()\n",
    "rmse2.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: How many diamonds are undervalued by the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred_pyt < y_test_pyt.unsqueeze(1)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we're here with PyTorch, we might as well try a more legit multilayer perceptron and see if we can do a little better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, D_in, H, D_out = 200, 26, 30, 1\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(D_in, H).double(),\n",
    "  torch.nn.ReLU(),\n",
    "  torch.nn.Linear(H, D_out).double()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "history = []\n",
    "for epoch in range(1500):\n",
    "    batch_losses = []\n",
    "    for i in range((len(train_ds) - 1) // batch_size + 1):\n",
    "        xb, yb = train_ds[i * batch_size: i * batch_size + batch_size]      \n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        batch_losses.append(loss.item()) # note the .item()\n",
    "    epoch_loss = np.sqrt(pd.Series(batch_losses).mean()) #not 100% accurate due to batch size diff, we'll fix that later\n",
    "    history.append(epoch_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Training sqrt-loss for epoch {} = {}\".format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpxh2P5Q78x5"
   },
   "outputs": [],
   "source": [
    "y_pred_pyt = model(X_test_pyt)\n",
    "rmse3 = torch.nn.MSELoss()(y_pred_pyt, y_test_pyt.unsqueeze(1)).sqrt()\n",
    "rmse3.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred_pyt.cuda() < y_test_pyt.unsqueeze(1).cuda()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "09-cuDF-and-PyTorch-Solvers.ipynb",
   "provenance": [
    {
     "file_id": "1tKG1FZPbCHSqp4kJx52wgnG9f7RW0Cvf",
     "timestamp": 1553029369447
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
